{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!pip install datatable > /dev/null\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import datatable as dt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "#PurgedGroupTimeSeriesSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\n",
    "from sklearn.utils.validation import _deprecate_positional_args\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tidalUtl.PrpUtl as prp\n",
    "import tidalUtl.EdaUtl as eda\n",
    "from sklearn.model_selection import GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified code for group gaps; source\n",
    "# https://github.com/getgaurav2/scikit-learn/blob/d4a3af5cc9da3a76f0266932644b884c99724c57/sklearn/model_selection/_split.py#L2243\n",
    "class PurgedGroupTimeSeriesSplit(_BaseKFold):\n",
    "    \"\"\"Time Series cross-validator variant with non-overlapping groups.\n",
    "    Allows for a gap in groups to avoid potentially leaking info from\n",
    "    train into test if the model has windowed or lag features.\n",
    "    Provides train/test indices to split time series data samples\n",
    "    that are observed at fixed time intervals according to a\n",
    "    third-party provided group.\n",
    "    In each split, test indices must be higher than before, and thus shuffling\n",
    "    in cross validator is inappropriate.\n",
    "    This cross-validation object is a variation of :class:`KFold`.\n",
    "    In the kth split, it returns first k folds as train set and the\n",
    "    (k+1)th fold as test set.\n",
    "    The same group will not appear in two different folds (the number of\n",
    "    distinct groups has to be at least equal to the number of folds).\n",
    "    Note that unlike standard cross-validation methods, successive\n",
    "    training sets are supersets of those that come before them.\n",
    "    Read more in the :ref:`User Guide <cross_validation>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=5\n",
    "        Number of splits. Must be at least 2.\n",
    "    max_train_group_size : int, default=Inf\n",
    "        Maximum group size for a single training set.\n",
    "    group_gap : int, default=None\n",
    "        Gap between train and test\n",
    "    max_test_group_size : int, default=Inf\n",
    "        We discard this number of groups from the end of each train split\n",
    "    \"\"\"\n",
    "\n",
    "    @_deprecate_positional_args\n",
    "    def __init__(self,\n",
    "                 n_splits=5,\n",
    "                 *,\n",
    "                 max_train_group_size=np.inf,\n",
    "                 max_test_group_size=np.inf,\n",
    "                 group_gap=None,\n",
    "                 verbose=False\n",
    "                 ):\n",
    "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
    "        self.max_train_group_size = max_train_group_size\n",
    "        self.group_gap = group_gap\n",
    "        self.max_test_group_size = max_test_group_size\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "        groups : array-like of shape (n_samples,)\n",
    "            Group labels for the samples used while splitting the dataset into\n",
    "            train/test set.\n",
    "        Yields\n",
    "        ------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        \"\"\"\n",
    "        if groups is None:\n",
    "            raise ValueError(\n",
    "                \"The 'groups' parameter should not be None\")\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        n_samples = _num_samples(X)\n",
    "        n_splits = self.n_splits\n",
    "        group_gap = self.group_gap\n",
    "        max_test_group_size = self.max_test_group_size\n",
    "        max_train_group_size = self.max_train_group_size\n",
    "        n_folds = n_splits + 1\n",
    "        group_dict = {}\n",
    "        u, ind = np.unique(groups, return_index=True)\n",
    "        unique_groups = u[np.argsort(ind)]\n",
    "        n_samples = _num_samples(X)\n",
    "        n_groups = _num_samples(unique_groups)\n",
    "        for idx in np.arange(n_samples):\n",
    "            if (groups[idx] in group_dict):\n",
    "                group_dict[groups[idx]].append(idx)\n",
    "            else:\n",
    "                group_dict[groups[idx]] = [idx]\n",
    "        if n_folds > n_groups:\n",
    "            raise ValueError(\n",
    "                (\"Cannot have number of folds={0} greater than\"\n",
    "                 \" the number of groups={1}\").format(n_folds,\n",
    "                                                     n_groups))\n",
    "\n",
    "        group_test_size = min(n_groups // n_folds, max_test_group_size)\n",
    "        group_test_starts = range(n_groups - n_splits * group_test_size,\n",
    "                                  n_groups, group_test_size)\n",
    "        for group_test_start in group_test_starts:\n",
    "            train_array = []\n",
    "            test_array = []\n",
    "\n",
    "            group_st = max(0, group_test_start - group_gap - max_train_group_size)\n",
    "            for train_group_idx in unique_groups[group_st:(group_test_start - group_gap)]:\n",
    "                train_array_tmp = group_dict[train_group_idx]\n",
    "                \n",
    "                train_array = np.sort(np.unique(\n",
    "                                      np.concatenate((train_array,\n",
    "                                                      train_array_tmp)),\n",
    "                                      axis=None), axis=None)\n",
    "\n",
    "            train_end = train_array.size\n",
    " \n",
    "            for test_group_idx in unique_groups[group_test_start:\n",
    "                                                group_test_start +\n",
    "                                                group_test_size]:\n",
    "                test_array_tmp = group_dict[test_group_idx]\n",
    "                test_array = np.sort(np.unique(\n",
    "                                              np.concatenate((test_array,\n",
    "                                                              test_array_tmp)),\n",
    "                                     axis=None), axis=None)\n",
    "\n",
    "            test_array  = test_array[group_gap:]\n",
    "            \n",
    "            \n",
    "            if self.verbose > 0:\n",
    "                    pass\n",
    "                    \n",
    "            yield [int(i) for i in train_array], [int(i) for i in test_array]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0+cu110\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ver1__<br>\n",
    "baseline：CV:0.01465 LB:0.01874<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"Pytorch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = \"/home/tidal/ML_Data/JaneStreet/jane-street-market-prediction\"\n",
    "OUTPUT = \"/home/tidal/ML_Data/JaneStreet/output\"\n",
    "#INPUT = \"/Users/hfuis/ML_Data/aneStreet/jane-street-market-prediction\"\n",
    "#OUTPUT = \"/Users/hfuis/ML_Data/aneStreet/jane-street-market-prediction\"\n",
    "\n",
    "SUBMIT = OUTPUT + \"/submittion/\"\n",
    "SAVEMODEL = OUTPUT + \"/model/\" + MODEL +\"/\"\n",
    "SAVEOOF = OUTPUT + \"/OOF/\" + MODEL +\"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.3 s, sys: 2.28 s, total: 22.6 s\n",
      "Wall time: 3.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Loading\n",
    "train_data_datatable = dt.fread(INPUT + '/train.csv')\n",
    "trainFeature = train_data_datatable.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in trainFeature.columns if 'feature' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seed固定\n",
    "def seed_everything(seed=42):\n",
    "    #data取得についてのランダム性固定\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    #cudnnによる演算の安定化(評価値の安定)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    #os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HyperParameter\n",
    "param_space = {'hidden_size1': 394, \n",
    "               'hidden_size2': 896, \n",
    "               'hidden_size3': 896, \n",
    "               'hidden_size4': 896, \n",
    "               'hidden_size5': 896, \n",
    "               'hidden_size6': 394, \n",
    "               'dropOutRate0': 0.10143786981358652, \n",
    "               'dropOutRate1': 0.19720339053599725,\n",
    "               'dropOutRate2': 0.2703017847244654,\n",
    "               'dropOutRate3': 0.23148340929571917,\n",
    "               'dropOutRate4': 0.2357768967777311,\n",
    "               'dropOutRate5': 0.2357768967777311,\n",
    "               'dropOutRate6': 0.2357768967777311,\n",
    "               'smoothingRate': 0.01,\n",
    "               \"actThrs\":0.5,\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>weight</th>\n",
       "      <th>resp_1</th>\n",
       "      <th>resp_2</th>\n",
       "      <th>resp_3</th>\n",
       "      <th>resp_4</th>\n",
       "      <th>resp</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_121</th>\n",
       "      <th>feature_122</th>\n",
       "      <th>feature_123</th>\n",
       "      <th>feature_124</th>\n",
       "      <th>feature_125</th>\n",
       "      <th>feature_126</th>\n",
       "      <th>feature_127</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>feature_129</th>\n",
       "      <th>ts_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009916</td>\n",
       "      <td>0.014079</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.872746</td>\n",
       "      <td>-2.191242</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.168391</td>\n",
       "      <td>8.313583</td>\n",
       "      <td>1.782433</td>\n",
       "      <td>14.018213</td>\n",
       "      <td>2.653056</td>\n",
       "      <td>12.600292</td>\n",
       "      <td>2.301488</td>\n",
       "      <td>11.445807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>16.673515</td>\n",
       "      <td>-0.002828</td>\n",
       "      <td>-0.003226</td>\n",
       "      <td>-0.007319</td>\n",
       "      <td>-0.011114</td>\n",
       "      <td>-0.009792</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.349537</td>\n",
       "      <td>-1.704709</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.178850</td>\n",
       "      <td>1.777472</td>\n",
       "      <td>-0.915458</td>\n",
       "      <td>2.831612</td>\n",
       "      <td>-1.417010</td>\n",
       "      <td>2.297459</td>\n",
       "      <td>-1.304614</td>\n",
       "      <td>1.898684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025134</td>\n",
       "      <td>0.027607</td>\n",
       "      <td>0.033406</td>\n",
       "      <td>0.034380</td>\n",
       "      <td>0.023970</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.812780</td>\n",
       "      <td>-0.256156</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.115747</td>\n",
       "      <td>9.667908</td>\n",
       "      <td>5.542871</td>\n",
       "      <td>11.671595</td>\n",
       "      <td>7.281757</td>\n",
       "      <td>10.060014</td>\n",
       "      <td>6.638248</td>\n",
       "      <td>9.427299</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004730</td>\n",
       "      <td>-0.003273</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>-0.000476</td>\n",
       "      <td>-0.003200</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.174378</td>\n",
       "      <td>0.344640</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.838853</td>\n",
       "      <td>0.499251</td>\n",
       "      <td>3.033732</td>\n",
       "      <td>1.513488</td>\n",
       "      <td>4.397532</td>\n",
       "      <td>1.266037</td>\n",
       "      <td>3.856384</td>\n",
       "      <td>1.013469</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.138531</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>-0.001215</td>\n",
       "      <td>-0.006219</td>\n",
       "      <td>-0.002604</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.172026</td>\n",
       "      <td>-3.093182</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.344850</td>\n",
       "      <td>4.101145</td>\n",
       "      <td>0.614252</td>\n",
       "      <td>6.623456</td>\n",
       "      <td>0.800129</td>\n",
       "      <td>5.233243</td>\n",
       "      <td>0.362636</td>\n",
       "      <td>3.926633</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390486</th>\n",
       "      <td>499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.005829</td>\n",
       "      <td>0.020342</td>\n",
       "      <td>0.015396</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.649365</td>\n",
       "      <td>-1.169996</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.896874</td>\n",
       "      <td>-1.260055</td>\n",
       "      <td>1.947725</td>\n",
       "      <td>-1.994399</td>\n",
       "      <td>-1.685163</td>\n",
       "      <td>-2.866165</td>\n",
       "      <td>-0.216130</td>\n",
       "      <td>-1.892048</td>\n",
       "      <td>0.901585</td>\n",
       "      <td>2390486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390487</th>\n",
       "      <td>499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000935</td>\n",
       "      <td>-0.006326</td>\n",
       "      <td>-0.004718</td>\n",
       "      <td>1</td>\n",
       "      <td>2.432943</td>\n",
       "      <td>5.284504</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.936553</td>\n",
       "      <td>1.064936</td>\n",
       "      <td>3.119762</td>\n",
       "      <td>-0.419796</td>\n",
       "      <td>-0.208975</td>\n",
       "      <td>-0.146749</td>\n",
       "      <td>0.730166</td>\n",
       "      <td>0.648452</td>\n",
       "      <td>2.068737</td>\n",
       "      <td>2390487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390488</th>\n",
       "      <td>499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.024907</td>\n",
       "      <td>0.016591</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.622475</td>\n",
       "      <td>-0.963682</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.956745</td>\n",
       "      <td>-0.640334</td>\n",
       "      <td>-2.279663</td>\n",
       "      <td>-0.950259</td>\n",
       "      <td>-4.388417</td>\n",
       "      <td>-1.669922</td>\n",
       "      <td>-3.288939</td>\n",
       "      <td>-1.336142</td>\n",
       "      <td>-2.814239</td>\n",
       "      <td>2390488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390489</th>\n",
       "      <td>499</td>\n",
       "      <td>0.283405</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.001375</td>\n",
       "      <td>-0.003702</td>\n",
       "      <td>-0.002004</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.463757</td>\n",
       "      <td>-1.107228</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.035894</td>\n",
       "      <td>-1.780962</td>\n",
       "      <td>0.881246</td>\n",
       "      <td>-2.202140</td>\n",
       "      <td>-1.912601</td>\n",
       "      <td>-3.341684</td>\n",
       "      <td>-0.571188</td>\n",
       "      <td>-2.185795</td>\n",
       "      <td>0.627452</td>\n",
       "      <td>2390489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390490</th>\n",
       "      <td>499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001855</td>\n",
       "      <td>-0.001855</td>\n",
       "      <td>-0.001194</td>\n",
       "      <td>-0.000864</td>\n",
       "      <td>-0.001905</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.817184</td>\n",
       "      <td>-1.131577</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.571013</td>\n",
       "      <td>2.483421</td>\n",
       "      <td>8.284037</td>\n",
       "      <td>-0.698486</td>\n",
       "      <td>0.199953</td>\n",
       "      <td>-0.168395</td>\n",
       "      <td>2.051091</td>\n",
       "      <td>1.726072</td>\n",
       "      <td>5.823676</td>\n",
       "      <td>2390490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2390491 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     weight    resp_1    resp_2    resp_3    resp_4      resp  \\\n",
       "0           0   0.000000  0.009916  0.014079  0.008773  0.001390  0.006270   \n",
       "1           0  16.673515 -0.002828 -0.003226 -0.007319 -0.011114 -0.009792   \n",
       "2           0   0.000000  0.025134  0.027607  0.033406  0.034380  0.023970   \n",
       "3           0   0.000000 -0.004730 -0.003273 -0.000461 -0.000476 -0.003200   \n",
       "4           0   0.138531  0.001252  0.002165 -0.001215 -0.006219 -0.002604   \n",
       "...       ...        ...       ...       ...       ...       ...       ...   \n",
       "2390486   499   0.000000  0.000142  0.000142  0.005829  0.020342  0.015396   \n",
       "2390487   499   0.000000  0.000012  0.000012 -0.000935 -0.006326 -0.004718   \n",
       "2390488   499   0.000000  0.000499  0.000499  0.007605  0.024907  0.016591   \n",
       "2390489   499   0.283405 -0.000156 -0.000156 -0.001375 -0.003702 -0.002004   \n",
       "2390490   499   0.000000 -0.001855 -0.001855 -0.001194 -0.000864 -0.001905   \n",
       "\n",
       "         feature_0  feature_1  feature_2  ...  feature_121  feature_122  \\\n",
       "0                1  -1.872746  -2.191242  ...          NaN     1.168391   \n",
       "1               -1  -1.349537  -1.704709  ...          NaN    -1.178850   \n",
       "2               -1   0.812780  -0.256156  ...          NaN     6.115747   \n",
       "3               -1   1.174378   0.344640  ...          NaN     2.838853   \n",
       "4                1  -3.172026  -3.093182  ...          NaN     0.344850   \n",
       "...            ...        ...        ...  ...          ...          ...   \n",
       "2390486          1  -1.649365  -1.169996  ...    -1.896874    -1.260055   \n",
       "2390487          1   2.432943   5.284504  ...    -0.936553     1.064936   \n",
       "2390488          1  -0.622475  -0.963682  ...    -2.956745    -0.640334   \n",
       "2390489         -1  -1.463757  -1.107228  ...    -2.035894    -1.780962   \n",
       "2390490         -1  -1.817184  -1.131577  ...    -0.571013     2.483421   \n",
       "\n",
       "         feature_123  feature_124  feature_125  feature_126  feature_127  \\\n",
       "0           8.313583     1.782433    14.018213     2.653056    12.600292   \n",
       "1           1.777472    -0.915458     2.831612    -1.417010     2.297459   \n",
       "2           9.667908     5.542871    11.671595     7.281757    10.060014   \n",
       "3           0.499251     3.033732     1.513488     4.397532     1.266037   \n",
       "4           4.101145     0.614252     6.623456     0.800129     5.233243   \n",
       "...              ...          ...          ...          ...          ...   \n",
       "2390486     1.947725    -1.994399    -1.685163    -2.866165    -0.216130   \n",
       "2390487     3.119762    -0.419796    -0.208975    -0.146749     0.730166   \n",
       "2390488    -2.279663    -0.950259    -4.388417    -1.669922    -3.288939   \n",
       "2390489     0.881246    -2.202140    -1.912601    -3.341684    -0.571188   \n",
       "2390490     8.284037    -0.698486     0.199953    -0.168395     2.051091   \n",
       "\n",
       "         feature_128  feature_129    ts_id  \n",
       "0           2.301488    11.445807        0  \n",
       "1          -1.304614     1.898684        1  \n",
       "2           6.638248     9.427299        2  \n",
       "3           3.856384     1.013469        3  \n",
       "4           0.362636     3.926633        4  \n",
       "...              ...          ...      ...  \n",
       "2390486    -1.892048     0.901585  2390486  \n",
       "2390487     0.648452     2.068737  2390487  \n",
       "2390488    -1.336142    -2.814239  2390488  \n",
       "2390489    -2.185795     0.627452  2390489  \n",
       "2390490     1.726072     5.823676  2390490  \n",
       "\n",
       "[2390491 rows x 138 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_0',\n",
       " 'feature_1',\n",
       " 'feature_2',\n",
       " 'feature_3',\n",
       " 'feature_4',\n",
       " 'feature_5',\n",
       " 'feature_6',\n",
       " 'feature_7',\n",
       " 'feature_8',\n",
       " 'feature_9',\n",
       " 'feature_10',\n",
       " 'feature_11',\n",
       " 'feature_12',\n",
       " 'feature_13',\n",
       " 'feature_14',\n",
       " 'feature_15',\n",
       " 'feature_16',\n",
       " 'feature_17',\n",
       " 'feature_18',\n",
       " 'feature_19',\n",
       " 'feature_20',\n",
       " 'feature_21',\n",
       " 'feature_22',\n",
       " 'feature_23',\n",
       " 'feature_24',\n",
       " 'feature_25',\n",
       " 'feature_26',\n",
       " 'feature_27',\n",
       " 'feature_28',\n",
       " 'feature_29',\n",
       " 'feature_30',\n",
       " 'feature_31',\n",
       " 'feature_32',\n",
       " 'feature_33',\n",
       " 'feature_34',\n",
       " 'feature_35',\n",
       " 'feature_36',\n",
       " 'feature_37',\n",
       " 'feature_38',\n",
       " 'feature_39',\n",
       " 'feature_40',\n",
       " 'feature_41',\n",
       " 'feature_42',\n",
       " 'feature_43',\n",
       " 'feature_44',\n",
       " 'feature_45',\n",
       " 'feature_46',\n",
       " 'feature_47',\n",
       " 'feature_48',\n",
       " 'feature_49',\n",
       " 'feature_50',\n",
       " 'feature_51',\n",
       " 'feature_52',\n",
       " 'feature_53',\n",
       " 'feature_54',\n",
       " 'feature_55',\n",
       " 'feature_56',\n",
       " 'feature_57',\n",
       " 'feature_58',\n",
       " 'feature_59',\n",
       " 'feature_60',\n",
       " 'feature_61',\n",
       " 'feature_62',\n",
       " 'feature_63',\n",
       " 'feature_64',\n",
       " 'feature_65',\n",
       " 'feature_66',\n",
       " 'feature_67',\n",
       " 'feature_68',\n",
       " 'feature_69',\n",
       " 'feature_70',\n",
       " 'feature_71',\n",
       " 'feature_72',\n",
       " 'feature_73',\n",
       " 'feature_74',\n",
       " 'feature_75',\n",
       " 'feature_76',\n",
       " 'feature_77',\n",
       " 'feature_78',\n",
       " 'feature_79',\n",
       " 'feature_80',\n",
       " 'feature_81',\n",
       " 'feature_82',\n",
       " 'feature_83',\n",
       " 'feature_84',\n",
       " 'feature_85',\n",
       " 'feature_86',\n",
       " 'feature_87',\n",
       " 'feature_88',\n",
       " 'feature_89',\n",
       " 'feature_90',\n",
       " 'feature_91',\n",
       " 'feature_92',\n",
       " 'feature_93',\n",
       " 'feature_94',\n",
       " 'feature_95',\n",
       " 'feature_96',\n",
       " 'feature_97',\n",
       " 'feature_98',\n",
       " 'feature_99',\n",
       " 'feature_100',\n",
       " 'feature_101',\n",
       " 'feature_102',\n",
       " 'feature_103',\n",
       " 'feature_104',\n",
       " 'feature_105',\n",
       " 'feature_106',\n",
       " 'feature_107',\n",
       " 'feature_108',\n",
       " 'feature_109',\n",
       " 'feature_110',\n",
       " 'feature_111',\n",
       " 'feature_112',\n",
       " 'feature_113',\n",
       " 'feature_114',\n",
       " 'feature_115',\n",
       " 'feature_116',\n",
       " 'feature_117',\n",
       " 'feature_118',\n",
       " 'feature_119',\n",
       " 'feature_120',\n",
       " 'feature_121',\n",
       " 'feature_122',\n",
       " 'feature_123',\n",
       " 'feature_124',\n",
       " 'feature_125',\n",
       " 'feature_126',\n",
       " 'feature_127',\n",
       " 'feature_128',\n",
       " 'feature_129']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Func: In & Out Type is DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FillNAN(trainFeature_inp):\n",
    "    #trainFeature = trainFeature_inp.copy()\n",
    "    trainFeature = trainFeature_inp\n",
    "    \n",
    "    f_mean = trainFeature[features[1:]].mean()\n",
    "    trainFeature = trainFeature.query('weight > 0').reset_index(drop = True)\n",
    "    \n",
    "    #欠損値を平均で埋める\n",
    "    trainFeature[features[1:]] = trainFeature[features[1:]].fillna(f_mean)\n",
    "    \n",
    "    #targetを生成\n",
    "    trainFeature['action'] = (trainFeature['resp'] > 0).astype('int')\n",
    "    \n",
    "    \n",
    "    \n",
    "    return trainFeature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__train,testにターゲット値も連結__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Collecting(trainFeature_inp):\n",
    "    #trainFeature = trainFeature_inp.copy()\n",
    "    trainFeature = trainFeature_inp\n",
    "    \n",
    "    #targetを生成\n",
    "    trainFeature['action'] = (trainFeature['resp'] > 0).astype('int')\n",
    "    \n",
    "    #target単体でも保持。\n",
    "    target = trainFeature['action'].copy()\n",
    "    target = pd.DataFrame(target,columns=[\"action\"])\n",
    "    return trainFeature, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(param, trainFeature):\n",
    "    \n",
    "    #欠損値処理\n",
    "    trainFeature = FillNAN(trainFeature)\n",
    "    \n",
    "    #trainにターゲット値を連結。\n",
    "    train, target = Collecting(trainFeature)\n",
    "    \n",
    "    \n",
    "    return train, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.75 s, sys: 756 ms, total: 3.51 s\n",
      "Wall time: 3.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainVsl, targetVsl = preprocessing(param_space, trainFeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>weight</th>\n",
       "      <th>resp_1</th>\n",
       "      <th>resp_2</th>\n",
       "      <th>resp_3</th>\n",
       "      <th>resp_4</th>\n",
       "      <th>resp</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_122</th>\n",
       "      <th>feature_123</th>\n",
       "      <th>feature_124</th>\n",
       "      <th>feature_125</th>\n",
       "      <th>feature_126</th>\n",
       "      <th>feature_127</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>feature_129</th>\n",
       "      <th>ts_id</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>16.673515</td>\n",
       "      <td>-0.002828</td>\n",
       "      <td>-0.003226</td>\n",
       "      <td>-0.007319</td>\n",
       "      <td>-0.011114</td>\n",
       "      <td>-0.009792</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.349537</td>\n",
       "      <td>-1.704709</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.178850</td>\n",
       "      <td>1.777472</td>\n",
       "      <td>-0.915458</td>\n",
       "      <td>2.831612</td>\n",
       "      <td>-1.417010</td>\n",
       "      <td>2.297459</td>\n",
       "      <td>-1.304614</td>\n",
       "      <td>1.898684</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.138531</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>-0.001215</td>\n",
       "      <td>-0.006219</td>\n",
       "      <td>-0.002604</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.172026</td>\n",
       "      <td>-3.093182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344850</td>\n",
       "      <td>4.101145</td>\n",
       "      <td>0.614252</td>\n",
       "      <td>6.623456</td>\n",
       "      <td>0.800129</td>\n",
       "      <td>5.233243</td>\n",
       "      <td>0.362636</td>\n",
       "      <td>3.926633</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.190575</td>\n",
       "      <td>-0.001939</td>\n",
       "      <td>-0.002301</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>0.005963</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3.172026</td>\n",
       "      <td>-3.093182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336873</td>\n",
       "      <td>4.076447</td>\n",
       "      <td>0.614783</td>\n",
       "      <td>6.622176</td>\n",
       "      <td>0.800618</td>\n",
       "      <td>5.231595</td>\n",
       "      <td>0.361506</td>\n",
       "      <td>3.921714</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3.820844</td>\n",
       "      <td>0.017395</td>\n",
       "      <td>0.021361</td>\n",
       "      <td>0.031163</td>\n",
       "      <td>0.036970</td>\n",
       "      <td>0.033473</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.446050</td>\n",
       "      <td>-0.466210</td>\n",
       "      <td>...</td>\n",
       "      <td>2.101997</td>\n",
       "      <td>4.846202</td>\n",
       "      <td>1.479875</td>\n",
       "      <td>5.261328</td>\n",
       "      <td>2.305066</td>\n",
       "      <td>4.571762</td>\n",
       "      <td>2.201537</td>\n",
       "      <td>4.429745</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.116557</td>\n",
       "      <td>-0.005460</td>\n",
       "      <td>-0.007301</td>\n",
       "      <td>-0.009085</td>\n",
       "      <td>-0.003546</td>\n",
       "      <td>-0.001677</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.172026</td>\n",
       "      <td>-3.093182</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537913</td>\n",
       "      <td>4.785838</td>\n",
       "      <td>1.637435</td>\n",
       "      <td>6.968002</td>\n",
       "      <td>2.354338</td>\n",
       "      <td>5.825499</td>\n",
       "      <td>1.778029</td>\n",
       "      <td>4.740577</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   date     weight    resp_1    resp_2    resp_3    resp_4      resp  \\\n",
       "0     0  16.673515 -0.002828 -0.003226 -0.007319 -0.011114 -0.009792   \n",
       "1     0   0.138531  0.001252  0.002165 -0.001215 -0.006219 -0.002604   \n",
       "2     0   0.190575 -0.001939 -0.002301  0.001088  0.005963  0.000709   \n",
       "3     0   3.820844  0.017395  0.021361  0.031163  0.036970  0.033473   \n",
       "4     0   0.116557 -0.005460 -0.007301 -0.009085 -0.003546 -0.001677   \n",
       "\n",
       "   feature_0  feature_1  feature_2  ...  feature_122  feature_123  \\\n",
       "0         -1  -1.349537  -1.704709  ...    -1.178850     1.777472   \n",
       "1          1  -3.172026  -3.093182  ...     0.344850     4.101145   \n",
       "2         -1  -3.172026  -3.093182  ...     0.336873     4.076447   \n",
       "3         -1   0.446050  -0.466210  ...     2.101997     4.846202   \n",
       "4          1  -3.172026  -3.093182  ...     1.537913     4.785838   \n",
       "\n",
       "   feature_124  feature_125  feature_126  feature_127  feature_128  \\\n",
       "0    -0.915458     2.831612    -1.417010     2.297459    -1.304614   \n",
       "1     0.614252     6.623456     0.800129     5.233243     0.362636   \n",
       "2     0.614783     6.622176     0.800618     5.231595     0.361506   \n",
       "3     1.479875     5.261328     2.305066     4.571762     2.201537   \n",
       "4     1.637435     6.968002     2.354338     5.825499     1.778029   \n",
       "\n",
       "   feature_129  ts_id  action  \n",
       "0     1.898684      1       0  \n",
       "1     3.926633      4       0  \n",
       "2     3.921714      6       1  \n",
       "3     4.429745      7       1  \n",
       "4     4.740577      8       0  \n",
       "\n",
       "[5 rows x 139 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainVsl.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   action\n",
       "0       0\n",
       "1       0\n",
       "2       1\n",
       "3       1\n",
       "4       0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetVsl.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "action\n",
       "1         999387\n",
       "0         981900\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetVsl.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(targetVsl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1981287, 139)\n",
      "Target: (1981287, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \"+ str(trainVsl.shape))\n",
    "print(\"Target: \"+ str(targetVsl.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: feature_3   number: 448\n",
      "Column: feature_4   number: 448\n",
      "Column: feature_7   number: 393135\n",
      "Column: feature_8   number: 393135\n",
      "Column: feature_9   number: 788\n",
      "Column: feature_10   number: 788\n",
      "Column: feature_11   number: 80015\n",
      "Column: feature_12   number: 80015\n",
      "Column: feature_13   number: 15353\n",
      "Column: feature_14   number: 15353\n",
      "Column: feature_15   number: 6683\n",
      "Column: feature_16   number: 6683\n",
      "Column: feature_17   number: 395535\n",
      "Column: feature_18   number: 395535\n",
      "Column: feature_19   number: 788\n",
      "Column: feature_20   number: 788\n",
      "Column: feature_21   number: 81444\n",
      "Column: feature_22   number: 81444\n",
      "Column: feature_23   number: 15353\n",
      "Column: feature_24   number: 15353\n",
      "Column: feature_25   number: 6683\n",
      "Column: feature_26   number: 6683\n",
      "Column: feature_27   number: 395535\n",
      "Column: feature_28   number: 395535\n",
      "Column: feature_29   number: 788\n",
      "Column: feature_30   number: 788\n",
      "Column: feature_31   number: 81444\n",
      "Column: feature_32   number: 81444\n",
      "Column: feature_33   number: 15353\n",
      "Column: feature_34   number: 15353\n",
      "Column: feature_35   number: 6683\n",
      "Column: feature_36   number: 6683\n",
      "Column: feature_44   number: 448\n",
      "Column: feature_45   number: 448\n",
      "Column: feature_55   number: 68409\n",
      "Column: feature_56   number: 719\n",
      "Column: feature_58   number: 1\n",
      "Column: feature_59   number: 48\n",
      "Column: feature_72   number: 351426\n",
      "Column: feature_73   number: 788\n",
      "Column: feature_74   number: 64088\n",
      "Column: feature_75   number: 15353\n",
      "Column: feature_76   number: 6683\n",
      "Column: feature_78   number: 351426\n",
      "Column: feature_79   number: 788\n",
      "Column: feature_80   number: 64088\n",
      "Column: feature_81   number: 15353\n",
      "Column: feature_82   number: 6683\n",
      "Column: feature_84   number: 351426\n",
      "Column: feature_85   number: 788\n",
      "Column: feature_86   number: 64088\n",
      "Column: feature_87   number: 15353\n",
      "Column: feature_88   number: 6683\n",
      "Column: feature_90   number: 351426\n",
      "Column: feature_91   number: 788\n",
      "Column: feature_92   number: 64088\n",
      "Column: feature_93   number: 15353\n",
      "Column: feature_94   number: 6683\n",
      "Column: feature_96   number: 351426\n",
      "Column: feature_97   number: 788\n",
      "Column: feature_98   number: 64088\n",
      "Column: feature_99   number: 15353\n",
      "Column: feature_100   number: 6683\n",
      "Column: feature_102   number: 351426\n",
      "Column: feature_103   number: 788\n",
      "Column: feature_104   number: 64088\n",
      "Column: feature_105   number: 15353\n",
      "Column: feature_106   number: 6683\n",
      "Column: feature_108   number: 351426\n",
      "Column: feature_109   number: 788\n",
      "Column: feature_110   number: 64088\n",
      "Column: feature_111   number: 15353\n",
      "Column: feature_112   number: 6683\n",
      "Column: feature_114   number: 351426\n",
      "Column: feature_115   number: 788\n",
      "Column: feature_116   number: 64088\n",
      "Column: feature_117   number: 15353\n",
      "Column: feature_118   number: 6683\n",
      "Column: feature_120   number: 69854\n",
      "Column: feature_121   number: 69854\n",
      "Column: feature_122   number: 223\n",
      "Column: feature_123   number: 223\n",
      "Column: feature_124   number: 16083\n",
      "Column: feature_125   number: 16083\n",
      "Column: feature_126   number: 8853\n",
      "Column: feature_127   number: 8853\n",
      "Column: feature_128   number: 1921\n",
      "Column: feature_129   number: 1921\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dfColumnNm</th>\n",
       "      <th>null</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feature_4</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feature_7</td>\n",
       "      <td>393135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feature_8</td>\n",
       "      <td>393135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feature_9</td>\n",
       "      <td>788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>feature_125</td>\n",
       "      <td>16083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>feature_126</td>\n",
       "      <td>8853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>feature_127</td>\n",
       "      <td>8853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>feature_128</td>\n",
       "      <td>1921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>feature_129</td>\n",
       "      <td>1921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dfColumnNm    null\n",
       "0          date       0\n",
       "1     feature_4     448\n",
       "2     feature_7  393135\n",
       "3     feature_8  393135\n",
       "4     feature_9     788\n",
       "..          ...     ...\n",
       "83  feature_125   16083\n",
       "84  feature_126    8853\n",
       "85  feature_127    8853\n",
       "86  feature_128    1921\n",
       "87  feature_129    1921\n",
       "\n",
       "[88 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda.chkDfIsNull(trainFeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is not NULL.\n"
     ]
    }
   ],
   "source": [
    "eda.chkDfIsNull(trainVsl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config about Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configは辞書化しておく。\n",
    "def Config_about_Fitting(train, target):\n",
    "    confFitting = {}\n",
    "    \n",
    "    #Fitするときに\"y\"として使う列の列名配列\n",
    "    confFitting[\"target_cols\"] = target.columns.values.tolist()\n",
    "    #Fitするときに\"X\"として使う列の列名配列\n",
    "    #kfold, id等はここで削除。\n",
    "    #feature_cols = [c for c in train.columns if c not in confFitting[\"target_cols\"]]\n",
    "    #confFitting[\"feature_cols\"] = [c for c in feature_cols if c not in ['kfold']]\n",
    "    confFitting[\"feature_cols\"] = features\n",
    "    #特徴量、ターゲットのサイズ\n",
    "    confFitting[\"num_features\"]=len(confFitting[\"feature_cols\"])\n",
    "    confFitting[\"num_targets\"]=len(confFitting[\"target_cols\"])\n",
    "    \n",
    "    return confFitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train,Valid用のデータクラス\n",
    "class TrainDataset:\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        #torch.DataLoaderに入れるための形式\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "#Test用のデータクラス\n",
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            #torch.DataLoaderに入れるための形式\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return dct\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss, Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
    "    def forward(self, x, target, smoothing):\n",
    "        confidence = 1. - smoothing\n",
    "        logprobs = F.log_softmax(x, dim=-1)\n",
    "        bcs_loss = nn.BCEWithLogitsLoss()(x, target)\n",
    "        smooth_loss = -logprobs.mean(dim=-1)\n",
    "        loss = confidence * bcs_loss + smoothing * smooth_loss\n",
    "        return loss.mean()\n",
    "\n",
    "#nn.functional.binary_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metric\n",
    "#roc_auc_score(y_val, oof[te])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Func: Fitting, Evaluation, Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device, cost, smoothingRate):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    \n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "#         print(inputs.shape)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(targets, outputs, smoothingRate)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step(cost)\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    valid_preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        #aucがsklearnなのでtorch tensorをnumpyに戻す。\n",
    "        outputs_ = outputs.to('cpu').detach().numpy().copy()\n",
    "        targets_ = targets.to('cpu').detach().numpy().copy()\n",
    "        loss = loss_fn(targets_, outputs_)\n",
    "        \n",
    "        del outputs_, targets_\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "    \n",
    "    return final_loss, valid_preds\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs = data['x'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return preds\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_features, num_targets, param):\n",
    "        super(Model, self).__init__()\n",
    "        #hyperoptによる被探索パラメータ\n",
    "        hidden_size1=param['hidden_size1']\n",
    "        hidden_size2=param['hidden_size2']\n",
    "        hidden_size3=param['hidden_size3']\n",
    "        hidden_size4=param['hidden_size4']\n",
    "        hidden_size5=param['hidden_size5']\n",
    "        hidden_size6=param['hidden_size6']\n",
    "        dropOutRate0=param['dropOutRate0']\n",
    "        dropOutRate1=param['dropOutRate1']\n",
    "        dropOutRate2=param['dropOutRate2']\n",
    "        dropOutRate3=param['dropOutRate3']\n",
    "        dropOutRate4=param['dropOutRate4']\n",
    "        dropOutRate5=param['dropOutRate5']\n",
    "        dropOutRate6=param['dropOutRate6']\n",
    "        #leakyReluSlope=param['leakyReluSlope']\n",
    "        \n",
    "        self.batch_norm0 = nn.BatchNorm1d(num_features)\n",
    "        self.dropout0 = nn.Dropout(dropOutRate0)\n",
    "        \n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size1))\n",
    "        self.Relu1 = nn.SiLU()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(hidden_size1)\n",
    "        self.dropout1 = nn.Dropout(dropOutRate1)\n",
    "        \n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(hidden_size1, hidden_size2))\n",
    "        self.Relu2 = nn.SiLU()\n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_size2)\n",
    "        self.dropout2 = nn.Dropout(dropOutRate2)\n",
    "        \n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size2, hidden_size3))\n",
    "        self.Relu3 = nn.SiLU()\n",
    "        self.batch_norm3 = nn.BatchNorm1d(hidden_size3)\n",
    "        self.dropout3 = nn.Dropout(dropOutRate3)\n",
    "        \n",
    "        self.dense4 = nn.utils.weight_norm(nn.Linear(hidden_size3, hidden_size4))\n",
    "        self.Relu4 = nn.SiLU()\n",
    "        self.batch_norm4 = nn.BatchNorm1d(hidden_size4)\n",
    "        self.dropout4 = nn.Dropout(dropOutRate4)\n",
    "        \n",
    "        self.dense5 = nn.utils.weight_norm(nn.Linear(hidden_size4, hidden_size5))\n",
    "        self.Relu5 = nn.SiLU()\n",
    "        self.batch_norm5 = nn.BatchNorm1d(hidden_size5)\n",
    "        self.dropout5 = nn.Dropout(dropOutRate5)\n",
    "        \n",
    "        self.dense6 = nn.utils.weight_norm(nn.Linear(hidden_size5, hidden_size6))\n",
    "        self.Relu6 = nn.SiLU()\n",
    "        self.batch_norm6 = nn.BatchNorm1d(hidden_size6)\n",
    "        self.dropout6 = nn.Dropout(dropOutRate6)\n",
    "        \n",
    "        self.dense7 = nn.utils.weight_norm(nn.Linear(hidden_size6, num_targets))\n",
    "        self.sigmoid1 = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm0(x)\n",
    "        x = self.dropout0(x)\n",
    "        \n",
    "        x = self.dense1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.Relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.dense2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.Relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.dense3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.Relu3(x)\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        x = self.dense4(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = self.Relu4(x)\n",
    "        x = self.dropout4(x)\n",
    "        \n",
    "        x = self.dense5(x)\n",
    "        x = self.batch_norm5(x)\n",
    "        x = self.Relu5(x)\n",
    "        x = self.dropout5(x)\n",
    "        \n",
    "        x = self.dense6(x)\n",
    "        x = self.batch_norm6(x)\n",
    "        x = self.Relu6(x)\n",
    "        x = self.dropout6(x)\n",
    "        \n",
    "        x = self.dense7(x)\n",
    "        x = self.sigmoid1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 4096\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 5\n",
    "EARLY_STOPPING_STEPS = 7\n",
    "EARLY_STOP = True\n",
    "GROUP_GAP = 31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_folds(train, target):\n",
    "    folds = train.copy()\n",
    "    \n",
    "    gkf = GroupKFold(n_splits=NFOLDS)\n",
    "    \n",
    "    for f, (t_idx, v_idx) in enumerate(gkf.split(train, target, train[\"date\"])):\n",
    "        folds.loc[v_idx, 'kfold'] = int(f)\n",
    "        #print(type(v_idx))\n",
    "        #print(v_idx.shape)\n",
    "    \n",
    "    folds['kfold'] = folds['kfold'].astype(int)\n",
    "    \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1->train, 0->valid, -1->使用なし\n",
    "def CV_folds_PurgedTimeSeries(train, target):\n",
    "    folds = train.copy()\n",
    "    \n",
    "    gkf = PurgedGroupTimeSeriesSplit(n_splits=NFOLDS, group_gap=GROUP_GAP)\n",
    "    \n",
    "    for f, (t_idx, v_idx) in enumerate(gkf.split(train.values, target.values, train[\"date\"].values)):\n",
    "        \n",
    "        folds.loc[t_idx, f'kfold_{f}'] = 1\n",
    "        folds.loc[v_idx, f'kfold_{f}'] = 0\n",
    "        folds[f'kfold_{f}'] = folds[f'kfold_{f}'].fillna(-1)\n",
    "        folds[f'kfold_{f}'] = folds[f'kfold_{f}'].astype(int)\n",
    "        #print(\"train:\",len(t_idx),\"  valid:\",len(v_idx))\n",
    "    \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.5 s, sys: 2.92 s, total: 22.4 s\n",
      "Wall time: 22.4 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>weight</th>\n",
       "      <th>resp_1</th>\n",
       "      <th>resp_2</th>\n",
       "      <th>resp_3</th>\n",
       "      <th>resp_4</th>\n",
       "      <th>resp</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_127</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>feature_129</th>\n",
       "      <th>ts_id</th>\n",
       "      <th>action</th>\n",
       "      <th>kfold_0</th>\n",
       "      <th>kfold_1</th>\n",
       "      <th>kfold_2</th>\n",
       "      <th>kfold_3</th>\n",
       "      <th>kfold_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>16.673515</td>\n",
       "      <td>-0.002828</td>\n",
       "      <td>-0.003226</td>\n",
       "      <td>-0.007319</td>\n",
       "      <td>-0.011114</td>\n",
       "      <td>-0.009792</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.349537</td>\n",
       "      <td>-1.704709</td>\n",
       "      <td>...</td>\n",
       "      <td>2.297459</td>\n",
       "      <td>-1.304614</td>\n",
       "      <td>1.898684</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.138531</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>-0.001215</td>\n",
       "      <td>-0.006219</td>\n",
       "      <td>-0.002604</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.172026</td>\n",
       "      <td>-3.093182</td>\n",
       "      <td>...</td>\n",
       "      <td>5.233243</td>\n",
       "      <td>0.362636</td>\n",
       "      <td>3.926633</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.190575</td>\n",
       "      <td>-0.001939</td>\n",
       "      <td>-0.002301</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>0.005963</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3.172026</td>\n",
       "      <td>-3.093182</td>\n",
       "      <td>...</td>\n",
       "      <td>5.231595</td>\n",
       "      <td>0.361506</td>\n",
       "      <td>3.921714</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3.820844</td>\n",
       "      <td>0.017395</td>\n",
       "      <td>0.021361</td>\n",
       "      <td>0.031163</td>\n",
       "      <td>0.036970</td>\n",
       "      <td>0.033473</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.446050</td>\n",
       "      <td>-0.466210</td>\n",
       "      <td>...</td>\n",
       "      <td>4.571762</td>\n",
       "      <td>2.201537</td>\n",
       "      <td>4.429745</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.116557</td>\n",
       "      <td>-0.005460</td>\n",
       "      <td>-0.007301</td>\n",
       "      <td>-0.009085</td>\n",
       "      <td>-0.003546</td>\n",
       "      <td>-0.001677</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.172026</td>\n",
       "      <td>-3.093182</td>\n",
       "      <td>...</td>\n",
       "      <td>5.825499</td>\n",
       "      <td>1.778029</td>\n",
       "      <td>4.740577</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   date     weight    resp_1    resp_2    resp_3    resp_4      resp  \\\n",
       "0     0  16.673515 -0.002828 -0.003226 -0.007319 -0.011114 -0.009792   \n",
       "1     0   0.138531  0.001252  0.002165 -0.001215 -0.006219 -0.002604   \n",
       "2     0   0.190575 -0.001939 -0.002301  0.001088  0.005963  0.000709   \n",
       "3     0   3.820844  0.017395  0.021361  0.031163  0.036970  0.033473   \n",
       "4     0   0.116557 -0.005460 -0.007301 -0.009085 -0.003546 -0.001677   \n",
       "\n",
       "   feature_0  feature_1  feature_2  ...  feature_127  feature_128  \\\n",
       "0         -1  -1.349537  -1.704709  ...     2.297459    -1.304614   \n",
       "1          1  -3.172026  -3.093182  ...     5.233243     0.362636   \n",
       "2         -1  -3.172026  -3.093182  ...     5.231595     0.361506   \n",
       "3         -1   0.446050  -0.466210  ...     4.571762     2.201537   \n",
       "4          1  -3.172026  -3.093182  ...     5.825499     1.778029   \n",
       "\n",
       "   feature_129  ts_id  action  kfold_0  kfold_1  kfold_2  kfold_3  kfold_4  \n",
       "0     1.898684      1       0        1        1        1        1        1  \n",
       "1     3.926633      4       0        1        1        1        1        1  \n",
       "2     3.921714      6       1        1        1        1        1        1  \n",
       "3     4.429745      7       1        1        1        1        1        1  \n",
       "4     4.740577      8       0        1        1        1        1        1  \n",
       "\n",
       "[5 rows x 144 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Preprocessing Data\n",
    "trainVsl, targetVsl = preprocessing(param_space, trainFeature)\n",
    "#CV folds\n",
    "foldsVsl= CV_folds_PurgedTimeSeries(trainVsl, targetVsl)\n",
    "\n",
    "foldsVsl.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    1445945\n",
       " 1     276588\n",
       " 0     258754\n",
       "Name: kfold_0, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foldsVsl[\"kfold_0\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    1486919\n",
       " 0     370311\n",
       "-1     124057\n",
       "Name: kfold_4, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foldsVsl[\"kfold_4\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utility_score_bincount(date, weight, resp, action):\n",
    "    #print(date.shape)\n",
    "    #print(weight.shape)\n",
    "    #print(resp.shape)\n",
    "    #print(action.shape)\n",
    "    #a = weight * resp * action\n",
    "    #print(a.shape)\n",
    "    \n",
    "    \n",
    "    count_i = len(np.unique(date))\n",
    "    Pi = np.bincount(date, weight * resp * action)\n",
    "    t = np.sum(Pi) / np.sqrt(np.sum(Pi ** 2)) * np.sqrt(250 / count_i)\n",
    "    u = np.clip(t, 0, 6) * np.sum(Pi)\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_Evaluation(confFitting, oof, train, fold, param):\n",
    "    \n",
    "    #print(len(train[confFitting[\"target_cols\"]]))\n",
    "    #print(len(oof))\n",
    "    train[confFitting[\"target_cols\"]] = oof\n",
    "    \n",
    "    #各引数の生成\n",
    "    date =  train[\"date\"].values\n",
    "    weight = train[\"weight\"].values\n",
    "    resp = train[\"resp\"].values\n",
    "    action = train[\"action\"].values\n",
    "    action = np.where(action >= param[\"actThrs\"], 1, 0).astype(int)\n",
    "    \n",
    "    #utility scoreの計算。\n",
    "    score = utility_score_bincount(date, weight, resp, action)\n",
    "        \n",
    "    print(\"Fold\", fold, \" CV utility score: \", score)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Fold Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(confFitting, Tester, fold, seed, param,\n",
    "                 folds, train, target):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    train = folds.copy()\n",
    "    \n",
    "    trn_idx = train[train[f'kfold_{fold}'] == 1].index\n",
    "    val_idx = train[train[f'kfold_{fold}'] == 0].index\n",
    "    \n",
    "    train_df = train[train[f'kfold_{fold}'] == 1].reset_index(drop=True)\n",
    "    valid_df = train[train[f'kfold_{fold}'] == 0].reset_index(drop=True)\n",
    "    \n",
    "    x_train, y_train  = train_df[confFitting[\"feature_cols\"]].values, train_df[confFitting[\"target_cols\"]].values\n",
    "    x_valid, y_valid =  valid_df[confFitting[\"feature_cols\"]].values, valid_df[confFitting[\"target_cols\"]].values\n",
    "    \n",
    "    #print(x_train.shape)\n",
    "    #print(x_train)\n",
    "    #print(y_train.shape)\n",
    "    #print(y_train)\n",
    "    \n",
    "    train_dataset = TrainDataset(x_train, y_train)\n",
    "    valid_dataset = TrainDataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=confFitting[\"num_features\"],\n",
    "        num_targets=confFitting[\"num_targets\"],\n",
    "        param=param\n",
    "    )\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    #scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "    #                                          max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, factor = 0.1, patience = 3, verbose = 0, mode = 'max')\n",
    "                      \n",
    "    ##### 評価関数 ######\n",
    "    train_loss_fn = LabelSmoothingCrossEntropy()\n",
    "    valid_loss_fn = roc_auc_score\n",
    "    \n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "    \n",
    "    oof = np.zeros((len(train), confFitting[\"num_targets\"]))\n",
    "    best_loss = 0\n",
    "    \n",
    "    #ReduceLROnPlateauのための初期値生成。\n",
    "    valid_loss, _ = valid_fn(model, valid_loss_fn, validloader, DEVICE)\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train_fn(model, optimizer,scheduler, train_loss_fn, trainloader, DEVICE, valid_loss, param['smoothingRate'])\n",
    "        valid_loss, valid_preds = valid_fn(model, valid_loss_fn, validloader, DEVICE)\n",
    "        \n",
    "        if Tester:\n",
    "            print(\"EPOCH: {:03}: | train_loss: {:.3f}: | valid_AUC: {:.3f}\".format(epoch, train_loss, valid_loss))\n",
    "        \n",
    "        if valid_loss > best_loss:\n",
    "            \n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            oof_evl = valid_preds\n",
    "            torch.save(model.state_dict(), f\"{SAVEMODEL}SEED{seed}_FOLD{fold}.pth\")\n",
    "        \n",
    "        elif(EARLY_STOP == True):\n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                if Tester:\n",
    "                    print('Early stopping. Best Val loss: {:.3f}'.format(best_loss))\n",
    "                break\n",
    "            \n",
    "    #foldごとのCV evaluation(utility score)\n",
    "    score = CV_Evaluation(confFitting, oof_evl, valid_df, fold, param)\n",
    "    \n",
    "    del train\n",
    "    \n",
    "    return oof\n",
    "    ################本コンペの仕様上テストデータがない#############################################\n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    #x_test = test[confFitting[\"feature_cols\"]].values\n",
    "    #testdataset = TestDataset(x_test)\n",
    "    #testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    #model = Model(\n",
    "    #    num_features=confFitting[\"num_features\"],\n",
    "    #    num_targets=confFitting[\"num_targets\"],\n",
    "    #    param=param\n",
    "    #)\n",
    "    #\n",
    "    #model.load_state_dict(torch.load(f\"{SAVEMODEL}SEED{seed}_FOLD{fold}.pth\"))\n",
    "    #model.to(DEVICE)\n",
    "    #\n",
    "    #predictions = np.zeros((len(test), target.iloc[:, 1:].shape[1]))\n",
    "    #predictions = inference_fn(model, testloader, DEVICE)\n",
    "    #\n",
    "    #\n",
    "    #return oof, predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold(Tester, NFOLDS, seed, param,\n",
    "              folds, train, target, confFitting):\n",
    "    oof = np.zeros((len(train), confFitting[\"num_targets\"]))\n",
    "    #predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        if Tester:\n",
    "            print('=' * 20, 'Fold', fold, '=' * 20)\n",
    "        oof_= run_training(confFitting, Tester, fold, seed, param,\n",
    "                                   folds, train, target)\n",
    "        \n",
    "        #predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    #return oof, predictions\n",
    "    return oof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特になし"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Submit(confFitting, predictions, test):\n",
    "    test[confFitting[\"target_cols\"]] = predictions\n",
    "    sub = sample_submission.drop(columns=confFitting[\"target_cols\"]).merge(test[['sig_id']+confFitting[\"target_cols\"]], on='sig_id', how='left').fillna(0)\n",
    "    sub.to_csv(f'{SUBMIT}submission.csv', index=False)\n",
    "\n",
    "    print(\"sub.shape\" + str(sub.shape))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Exec(param):\n",
    "    \n",
    "    #Tester(True/False)\n",
    "    Tester = True\n",
    "    \n",
    "    #Preprocessing Data\n",
    "    train, target = preprocessing(param_space, trainFeature)\n",
    "    \n",
    "    #CV folds\n",
    "    folds = CV_folds_PurgedTimeSeries(train, target)\n",
    "    \n",
    "    #Config about Fitting\n",
    "    confFitting = Config_about_Fitting(train, target)\n",
    "    \n",
    "    # Averaging on multiple SEEDS\n",
    "    #SEED = [0, 1, 2, 3 ,4, 5]\n",
    "    SEED = [42]\n",
    "    oof = np.zeros((len(train), confFitting[\"num_targets\"]))\n",
    "    #predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    ### RUN ###\n",
    "    for seed in SEED:\n",
    "        if Tester:\n",
    "            print('~' * 20, 'SEED', seed, '~' * 20)\n",
    "        oof_ = run_k_fold(Tester, NFOLDS, seed, param,\n",
    "                                       folds, train, target, confFitting)\n",
    "        oof += oof_ / len(SEED)\n",
    "        #predictions += predictions_ / len(SEED)\n",
    "    \n",
    "    #CV 評価\n",
    "    #utility\n",
    "    score_utl = CV_Evaluation(confFitting, oof, train, -1, param)\n",
    "    score_auc = roc_auc_score(target.values, oof)\n",
    "    print(\"CV AUC score: \", score_auc)\n",
    "    \n",
    "    \n",
    "    # 課題提出\n",
    "    #Submit(confFitting, predictions, test)\n",
    "    \n",
    "    #OOF save\n",
    "    np.save(SAVEOOF + 'oof', oof)\n",
    "    \n",
    "    return score_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~ SEED 42 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n",
      "EPOCH: 000: | train_loss: 0.656: | valid_AUC: 0.504\n",
      "EPOCH: 001: | train_loss: 0.652: | valid_AUC: 0.504\n",
      "EPOCH: 002: | train_loss: 0.653: | valid_AUC: 0.504\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-1f241811bd46>\u001b[0m in \u001b[0;36mExec\u001b[0;34m(param)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'~'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SEED'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'~'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         oof_ = run_k_fold(Tester, NFOLDS, seed, param,\n\u001b[0;32m---> 26\u001b[0;31m                                        folds, train, target, confFitting)\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0moof\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0moof_\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#predictions += predictions_ / len(SEED)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-a3938f991c8a>\u001b[0m in \u001b[0;36mrun_k_fold\u001b[0;34m(Tester, NFOLDS, seed, param, folds, train, target, confFitting)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'='\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Fold'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'='\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         oof_= run_training(confFitting, Tester, fold, seed, param,\n\u001b[0;32m---> 10\u001b[0;31m                                    folds, train, target)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#predictions += pred_ / NFOLDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-53181d4e9eb1>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(confFitting, Tester, fold, seed, param, folds, train, target)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'smoothingRate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-6c37a995ba90>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(model, optimizer, scheduler, loss_fn, dataloader, device, cost, smoothingRate)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#         print(inputs.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmoothingRate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-10de0037be40>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_norm3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRelu3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             self.weight, self.bias, bn_training, exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2056\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   2057\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2058\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2059\u001b[0m     )\n\u001b[1;32m   2060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "oof= Exec(param_space)\n",
    "#print(\"score: \" + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_predict(confFitting, param, test, target, fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "  \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test[confFitting[\"feature_cols\"]].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=confFitting[\"num_features\"],\n",
    "        num_targets=confFitting[\"num_targets\"],\n",
    "        param=param\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"{SAVEMODEL}SEED{seed}_FOLD{fold}.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold_predict(confFitting, test, target, param, Tester, NFOLDS, seed):\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        if Tester:\n",
    "            print('=' * 20, 'Fold', fold, '=' * 20)\n",
    "        pred_ = run_predict(confFitting, param, test, target, fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SubmitPredict(confFitting, predictions, test, prefix):\n",
    "    test[confFitting[\"target_cols\"]] = predictions\n",
    "    sub = sample_submission.drop(columns=confFitting[\"target_cols\"]).merge(test[['sig_id']+confFitting[\"target_cols\"]], on='sig_id', how='left').fillna(0)\n",
    "    sub.to_csv(f'{SUBMIT}{prefix}submission.csv', index=False)\n",
    "\n",
    "    print(\"sub.shape\" + str(sub.shape))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(param):\n",
    "    #Tester(True/False)\n",
    "    Tester = False\n",
    "    \n",
    "    #Preprocessing Data\n",
    "    train, target = preprocessing(param_space, trainFeature)\n",
    "    \n",
    "    #CV folds\n",
    "    folds = CV_folds(train, target)\n",
    "    \n",
    "    #Config about Fitting\n",
    "    confFitting = Config_about_Fitting(train, test, target, folds)\n",
    "    \n",
    "    # Averaging on multiple SEEDS\n",
    "    SEED = [0, 1, 2, 3 ,4, 5]\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    ### RUN ###\n",
    "    for seed in SEED:\n",
    "        if Tester:\n",
    "            print('~' * 20, 'SEED', seed, '~' * 20)\n",
    "        predictions_ = run_k_fold_predict(confFitting, test, target, param, Tester, NFOLDS, seed)\n",
    "        predictions += predictions_ / len(SEED)\n",
    "    \n",
    "    # 課題提出\n",
    "    prefix = \"\"\n",
    "    SubmitPredict(confFitting, predictions, test, prefix)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#Predict(param_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperopt\n",
    "from hyperopt import fmin, tpe, hp, rand, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 3.81 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#HyperParameter\n",
    "#param_space = {'hidden_size1': hp.choice('hidden_size1', [394, 512, 896, 1024]), \n",
    "#               'hidden_size2': hp.choice('hidden_size2', [394, 512, 896, 1024]), \n",
    "#               'hidden_size3': hp.choice('hidden_size3', [394, 512, 896, 1024]),\n",
    "#               'hidden_size4': hp.choice('hidden_size4', [394, 512, 896, 1024]),\n",
    "#               'hidden_size5': hp.choice('hidden_size5', [394, 512, 896, 1024]),\n",
    "#               'hidden_size6': hp.choice('hidden_size6', [394, 512, 896, 1024]),\n",
    "#               'dropOutRate0': hp.uniform('dropOutRate0', 0, 0.4), \n",
    "#               'dropOutRate1': hp.uniform('dropOutRate1', 0, 0.4),\n",
    "#               'dropOutRate2': hp.uniform('dropOutRate2', 0, 0.4),\n",
    "#               'dropOutRate3': hp.uniform('dropOutRate3', 0, 0.4),\n",
    "#               'dropOutRate4': hp.uniform('dropOutRate4', 0, 0.4),\n",
    "#               'dropOutRate5': hp.uniform('dropOutRate5', 0, 0.4),\n",
    "#               'dropOutRate6': hp.uniform('dropOutRate6', 0, 0.4),\n",
    "#               'smoothingRate': hp.loguniform('smoothingRate', -7, -2),\n",
    "#               'actThrs':hp.uniform('actThrs', 0, 1),\n",
    "#              }\n",
    "#\n",
    "#trials = Trials()\n",
    "#\n",
    "#hopt = fmin(fn = Exec, \n",
    "#            space = param_space, \n",
    "#            algo = tpe.suggest, \n",
    "#            max_evals = 25, \n",
    "#            #timeout = 8.9 * 60 * 60, \n",
    "#            trials = trials, \n",
    "#           )\n",
    "#\n",
    "#print(hopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
